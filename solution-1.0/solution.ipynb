{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd \n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.impute import KNNImputer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "random_seed = 2024"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## I. Data-Cleaning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. diet.csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AuthorId      object\n",
       "Diet        category\n",
       "Age            int64\n",
       "dtype: object"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "users_diet = pd.read_csv('../aufgabe/training_dataset/diet.csv')\n",
    "# print(users_diet.head())\n",
    "# users_diet.shape\n",
    "# users_diet.dtypes\n",
    "\n",
    "# Nullwerte\n",
    "# users_diet.isnull().sum()\n",
    "\n",
    "# 1. Spalte \"Diet\"\n",
    "# -> ein Nullwert drin \n",
    "#users_diet[users_diet[\"Diet\"].isna()]\n",
    "\n",
    "# Author 646062A ohne Wert für Diet -> Weg mit dem Hund\n",
    "users_diet = users_diet.drop(users_diet[users_diet[\"Diet\"].isna()].index).reset_index(drop=True)\n",
    "\n",
    "# Weitere missing values finden: z.B. <empty field>, \"0\", \".\", \"999\", \"NA\" ...\n",
    "# users_diet[(users_diet[\"Diet\"] == \"\") | (users_diet[\"Diet\"] == \".\") | (users_diet[\"Diet\"] == \"999\")]\n",
    "\n",
    "\n",
    "# 2. Spalte \"Age\"\n",
    "# users_diet[users_diet[\"Age\"] > 100]\n",
    "# users_diet[users_diet[\"Age\"] < 5]\n",
    "# print(\"Range Alter\", users_diet[\"Age\"].min(), users_diet[\"Age\"].max())\n",
    "\n",
    "# 3. Spalte \"AuthorId\"\n",
    "# print(\"Einzigartige IDs: \", users_diet[\"AuthorId\"].nunique(), users_diet.shape[0])\n",
    "\n",
    "\n",
    "# Datentyp bei \"Diet\" zu Category ändern\n",
    "users_diet[\"Diet\"] = users_diet['Diet'].astype(\"category\")\n",
    "users_diet.dtypes\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. reviews.csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/ld/b6k2sw2912sg5m2xrc0hr5qh0000gn/T/ipykernel_57720/894044532.py:1: DtypeWarning: Columns (3) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  reviews_data = pd.read_csv(\"../aufgabe/training_dataset/reviews.csv\")\n"
     ]
    }
   ],
   "source": [
    "reviews_data = pd.read_csv(\"../aufgabe/training_dataset/reviews.csv\")\n",
    "\n",
    "# Test-Daten -> TestSetId != NaN, die anderen nicht für Modelle verwenden\n",
    "reviews_data_test = reviews_data[reviews_data[\"TestSetId\"].isna()].reset_index(drop=True)\n",
    "reviews_data_test.loc[reviews_data_test['Rating'].isna(), \"Rating\"] = 999\n",
    "reviews_data_test[\"Rating\"] = reviews_data_test[\"Rating\"].astype(\"category\")\n",
    "\n",
    "# Like column zu boolean\n",
    "reviews_data_test[\"Like\"] = reviews_data_test[\"Like\"].astype(\"bool\")\n",
    "\n",
    "# reviews_data_test.dtypes\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. requests.csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "requests_data = pd.read_csv(\"../aufgabe/training_dataset/requests.csv\")\n",
    "requests_data.head()\n",
    "\n",
    "# Column: Time\n",
    "# Runden\n",
    "\"\"\" \n",
    "Column Time -> runden, da Nachkommastellen bei Kochzeit irrelevant\n",
    "Beschreibung: The duration a recipe should take at most (including the time reserved\n",
    "for the preparation and cooking).\n",
    "\"\"\"\n",
    "requests_data[\"Time\"] = requests_data[\"Time\"].round(1)\n",
    "\n",
    "# Teilweise negative Werte -> 0\n",
    "requests_data.loc[requests_data[\"Time\"] <= 0, \"Time\"] = 0\n",
    "\"\"\"\n",
    "Test, ob negative Werte immer False als \"Like\" haben -> stimmt aber nicht siehe Code:\n",
    "Requests mit [AuthorId, RecipeId] time <= 0 mit reviews [AuthorId, RecipeId] joinen und dort like checken\n",
    "joined_data = requests_data.merge(reviews_data_test, on=[\"AuthorId\", \"RecipeId\"], how=\"left\")\n",
    "joined_data = joined_data[joined_data[\"Time\"] <= 0]\n",
    "joined_data = joined_data[~joined_data[\"Like\"].isna()]\n",
    "\"\"\"\n",
    "\n",
    "# Column: HighCalories\n",
    "requests_data[\"HighCalories\"] = requests_data[\"HighCalories\"].astype(\"bool\")\n",
    "\n",
    "# Column: HighProtein\n",
    "\"\"\"\n",
    "2 Werte: Indifferent und Yes\n",
    "Daraus wird boolean indifferent = False und Yes = True\n",
    "\"\"\"\n",
    "requests_data.loc[requests_data[\"HighProtein\"] == \"Indifferent\", \"HighProtein\"] = 0\n",
    "requests_data.loc[requests_data[\"HighProtein\"] == \"Yes\", \"HighProtein\"] = 1\n",
    "requests_data[\"HighProtein\"] = requests_data[\"HighProtein\"].astype(\"bool\")\n",
    "\n",
    "# Column: LowFat\n",
    "requests_data[\"LowFat\"] = requests_data[\"LowFat\"].astype(\"bool\")\n",
    "\n",
    "# Column: LowSugar\n",
    "\"\"\"\n",
    "2 Werte: Indifferent und 0. Interpretation: 0 -> user braucht kein low-sugar Inhalt, Indifferent -> User ist es egal\n",
    "Daraus wird boolean 0 = False und indifferent = True\n",
    "\"\"\"\n",
    "requests_data.loc[requests_data[\"LowSugar\"] == \"0\", \"LowSugar\"] = 0\n",
    "requests_data.loc[requests_data[\"LowSugar\"] == \"Indifferent\", \"LowSugar\"] = 1\n",
    "requests_data[\"LowSugar\"] = requests_data[\"LowSugar\"].astype(\"bool\")\n",
    "\n",
    "# Column HighFiber\n",
    "requests_data[\"HighFiber\"] = requests_data[\"HighFiber\"].astype(\"bool\")\n",
    "\n",
    "# requests_data[\"HighFiber\"].unique()\n",
    "# requests_data.head(20)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4. recipes.csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape vorher:  (73253, 18)\n",
      "Shape nach Kürzung der Outlier:  (72073, 17)\n",
      "R Squared:  0.2908043238074334\n",
      "MSE Mean Squred Error:  0.17361849290447004\n",
      "       y_val  y_pred  RecipeId\n",
      "23717      1    1.00    446595\n",
      "24753      0    0.92     26389\n",
      "32151      0    0.24    117789\n",
      "21265      1    0.92     42256\n",
      "9118       0    0.42    238978\n",
      "43051      1    0.54    230105\n",
      "68551      0    0.30      4174\n",
      "15959      0    0.28     46544\n",
      "6868       0    0.20    334664\n",
      "59608      0    0.14       361\n",
      "51736      0    0.34    127257\n",
      "71585      0    0.24    361751\n",
      "46800      0    0.32    280855\n",
      "70073      1    0.54    414221\n",
      "61243      1    0.28    327645\n",
      "73773      0    0.24    179599\n",
      "32079      1    0.54    132565\n",
      "45637      0    0.14     79708\n",
      "17698      1    0.10    277619\n",
      "10983      1    0.62    130653\n"
     ]
    }
   ],
   "source": [
    "recipes_data = pd.read_csv(\"../aufgabe/training_dataset/recipes.csv\")\n",
    "threshold = 3.5\n",
    "\n",
    "# Column CookTime und Column PrepTime\n",
    "\"\"\"\n",
    "Outlier Detection:\n",
    "Außerhalb von 3,5*Standardabweichung -> Outlier\n",
    "\n",
    "=> Outlier werden entfernt\n",
    "\"\"\"\n",
    "# log transformation\n",
    "recipes_data[\"CookTime\"] = recipes_data[\"CookTime\"].apply(lambda x: np.log(x) if x > 0 else x)\n",
    "recipes_data[\"PrepTime\"] = recipes_data[\"PrepTime\"].apply(lambda x: np.log(x) if x > 0 else x)\n",
    "# print(recipes_data[\"PrepTime\"].describe())\n",
    "\n",
    "# plt.hist(recipes_data['PrepTime'], bins=10)\n",
    "# plt.title('Histogram of Cook Time')\n",
    "# plt.xlabel('Cook Time')\n",
    "# plt.ylabel('Frequency')\n",
    "# plt.show()\n",
    "\n",
    "std_CookTime = recipes_data['CookTime'].std()\n",
    "mean_CookTime = recipes_data['CookTime'].mean()\n",
    "upper_limit_CookTime = mean_CookTime + threshold * std_CookTime\n",
    "lower_limit_CookTime = mean_CookTime - threshold * std_CookTime\n",
    "\n",
    "\n",
    "std_PrepTime = recipes_data['PrepTime'].std()\n",
    "mean_PrepTime = recipes_data['PrepTime'].mean()\n",
    "upper_limit_PrepTime = mean_PrepTime + threshold * std_PrepTime\n",
    "lower_limit_PrepTime = mean_PrepTime - threshold * std_PrepTime\n",
    "\n",
    "recipes_data = recipes_data[(recipes_data[\"CookTime\"] >= lower_limit_CookTime) & (recipes_data['CookTime'] <= upper_limit_CookTime)]\n",
    "\n",
    "recipes_data = recipes_data[(recipes_data[\"PrepTime\"] >= lower_limit_PrepTime) & (recipes_data['PrepTime'] <= upper_limit_PrepTime)]\n",
    "print(\"Shape vorher: \", recipes_data.shape)\n",
    "\n",
    "\n",
    "# Column RecipeCategory\n",
    "recipes_data[\"RecipeCategory\"] = recipes_data[\"RecipeCategory\"].astype(\"category\")\n",
    "\n",
    "\n",
    "# Column RecipeIngredientQuantities und Column RecipeIngredientParts\n",
    "# zu liste von strings umwandeln\n",
    "recipes_data[\"RecipeIngredientQuantities\"] = recipes_data[\"RecipeIngredientQuantities\"].str.replace('character(0)', '').str.lstrip('\"c(\"').str.replace('\"', '').str.replace(\")\", \"\").str.replace('\\\\', '').str.split(\",\")\n",
    "recipes_data[\"RecipeIngredientParts\"] = recipes_data[\"RecipeIngredientParts\"].str.replace('character(0)', '').str.lstrip('\"c(\"').str.replace('\"', '').str.replace(\")\", \"\").str.replace('\\\\', '').str.split(\",\")\n",
    "\n",
    "\n",
    "# Column Calories\n",
    "# Outlier weg\n",
    "recipes_data[\"Calories\"] = recipes_data[\"Calories\"].apply(lambda x: np.log(x) if x > 0 else x)\n",
    "\n",
    "std_Calories = recipes_data['Calories'].std()\n",
    "mean_Calories = recipes_data['Calories'].mean()\n",
    "upper_limit_Calories = mean_Calories + threshold * std_Calories\n",
    "lower_limit_Calories = mean_Calories - threshold * std_Calories\n",
    "\n",
    "recipes_data = recipes_data[(recipes_data[\"Calories\"] >= lower_limit_Calories) & (recipes_data['Calories'] <= upper_limit_Calories)]\n",
    "\n",
    "\n",
    "# Column FatContent\n",
    "# Oulier weg\n",
    "\n",
    "recipes_data[\"FatContent\"] = recipes_data[\"FatContent\"].apply(lambda x: np.log(x+1) if x > 0 else x)\n",
    "\n",
    "std_FatContent = recipes_data['FatContent'].std()\n",
    "mean_FatContent = recipes_data['FatContent'].mean()\n",
    "upper_limit_FatContent = mean_FatContent + threshold * std_FatContent\n",
    "lower_limit_FatContent = mean_FatContent - threshold * std_FatContent\n",
    "\n",
    "recipes_data = recipes_data[(recipes_data[\"FatContent\"] >= lower_limit_FatContent) & (recipes_data['FatContent'] <= upper_limit_FatContent)]\n",
    "\n",
    "\n",
    "# Column SaturatedFatContent\n",
    "# Outlier weg\n",
    "recipes_data[\"SaturatedFatContent\"] = recipes_data[\"SaturatedFatContent\"].apply(lambda x: np.log(x+1) if x > 0 else x)\n",
    "\n",
    "std_SaturatedFatContent = recipes_data['SaturatedFatContent'].std()\n",
    "mean_SaturatedFatContent = recipes_data['SaturatedFatContent'].mean()\n",
    "upper_limit_SaturatedFatContent = mean_SaturatedFatContent + threshold * std_SaturatedFatContent\n",
    "lower_limit_SaturatedFatContent = mean_SaturatedFatContent - threshold * std_SaturatedFatContent\n",
    "\n",
    "recipes_data = recipes_data[(recipes_data[\"SaturatedFatContent\"] >= lower_limit_SaturatedFatContent) & (recipes_data['SaturatedFatContent'] <= upper_limit_SaturatedFatContent)]\n",
    "\n",
    "\n",
    "# Column CholesterolContent\n",
    "# Outlier weg\n",
    "recipes_data[\"CholesterolContent\"] = recipes_data[\"CholesterolContent\"].apply(lambda x: np.log(x + 1) if x > 0 else x)\n",
    "\n",
    "std_CholesterolContent = recipes_data['CholesterolContent'].std()\n",
    "mean_CholesterolContent = recipes_data['CholesterolContent'].mean()\n",
    "upper_limit_CholesterolContent = mean_CholesterolContent + threshold * std_CholesterolContent\n",
    "lower_limit_CholesterolContent = mean_CholesterolContent - threshold * std_CholesterolContent\n",
    "\n",
    "recipes_data = recipes_data[(recipes_data[\"CholesterolContent\"] >= lower_limit_CholesterolContent) & (recipes_data['CholesterolContent'] <= upper_limit_CholesterolContent)]\n",
    "\n",
    "\n",
    "# Column SodiumContent\n",
    "# Outlier weg\n",
    "recipes_data[\"SodiumContent\"] = recipes_data[\"SodiumContent\"].apply(lambda x: np.log(x + 1) if x > 0 else x)\n",
    "\n",
    "std_SodiumContent = recipes_data['SodiumContent'].std()\n",
    "mean_SodiumContent = recipes_data['SodiumContent'].mean()\n",
    "upper_limit_SodiumContent = mean_SodiumContent + threshold * std_SodiumContent\n",
    "lower_limit_SodiumContent = mean_SodiumContent - threshold * std_SodiumContent\n",
    "\n",
    "recipes_data = recipes_data[(recipes_data[\"SodiumContent\"] >= lower_limit_SodiumContent) & (recipes_data['SodiumContent'] <= upper_limit_SodiumContent)]\n",
    "\n",
    "\n",
    "# Column CarbohydrateContent\n",
    "# Outlier weg\n",
    "recipes_data[\"CarbohydrateContent\"] = recipes_data[\"CarbohydrateContent\"].apply(lambda x: np.log(x+1) if x > 0 else x)\n",
    "\n",
    "std_CarbohydrateContent = recipes_data['CarbohydrateContent'].std()\n",
    "mean_CarbohydrateContent = recipes_data['CarbohydrateContent'].mean()\n",
    "upper_limit_CarbohydrateContent = mean_CarbohydrateContent + threshold * std_CarbohydrateContent\n",
    "lower_limit_CarbohydrateContent = mean_CarbohydrateContent - threshold * std_CarbohydrateContent\n",
    "\n",
    "recipes_data = recipes_data[(recipes_data[\"CarbohydrateContent\"] >= lower_limit_CarbohydrateContent) & (recipes_data['CarbohydrateContent'] <= upper_limit_CarbohydrateContent)]\n",
    "\n",
    "\n",
    "# Column FiberContent\n",
    "# Outlier weg\n",
    "recipes_data[\"FiberContent\"] = recipes_data[\"FiberContent\"].apply(lambda x: np.log(x+1) if x > 0 else x)\n",
    "\n",
    "std_FiberContent = recipes_data['FiberContent'].std()\n",
    "mean_FiberContent = recipes_data['FiberContent'].mean()\n",
    "upper_limit_FiberContent = mean_FiberContent + threshold * std_FiberContent\n",
    "lower_limit_FiberContent = mean_FiberContent - threshold * std_FiberContent\n",
    "\n",
    "recipes_data = recipes_data[(recipes_data[\"FiberContent\"] >= lower_limit_FiberContent) & (recipes_data['FiberContent'] <= upper_limit_FiberContent)]\n",
    "\n",
    "\n",
    "# Column SugarContent\n",
    "# Outlier weg\n",
    "recipes_data[\"SugarContent\"] = recipes_data['SugarContent'].apply(lambda x: np.log(x+1) if x > 0 else x)\n",
    "\n",
    "std_SugarContent = recipes_data['SugarContent'].std()\n",
    "mean_SugarContent = recipes_data['SugarContent'].mean()\n",
    "upper_limit_SugarContent = mean_SugarContent + threshold * std_SugarContent\n",
    "lower_limit_SugarContent = mean_SugarContent - threshold * std_SugarContent\n",
    "\n",
    "recipes_data = recipes_data[(recipes_data[\"SugarContent\"] >= lower_limit_SugarContent) & (recipes_data['SugarContent'] <= upper_limit_SugarContent)]\n",
    "\n",
    "\n",
    "\n",
    "# Column ProteinContent\n",
    "# Outlier weg\n",
    "recipes_data[\"ProteinContent\"] = recipes_data[\"ProteinContent\"].apply(lambda x: np.log(x+1) if x > 0 else x)\n",
    "\n",
    "std_ProteinContent = recipes_data['ProteinContent'].std()\n",
    "mean_ProteinContent = recipes_data['ProteinContent'].mean()\n",
    "upper_limit_ProteinContent = mean_ProteinContent + threshold * std_ProteinContent\n",
    "lower_limit_ProteinContent = mean_ProteinContent - threshold * std_ProteinContent\n",
    "\n",
    "recipes_data = recipes_data[(recipes_data[\"ProteinContent\"] >= lower_limit_ProteinContent) & (recipes_data['ProteinContent'] <= upper_limit_ProteinContent)]\n",
    "\n",
    "\n",
    "# Column RecipeServings & Column RecipeYield\n",
    "\"\"\"\n",
    "RecipeServings: Anzahl der Portionen, die das Rezept ergibt\n",
    "RecipeYield: Gibt an, wie viele Stücke man aus dem Rezept erhält. Ein Rezept ergibt zum Beispiel 1/2 Liter Suppe, was 2 Portionen entspricht.\n",
    "-> Versuch: RecipeYield zu standardisieren z.B. in Liter, Gramm, Stück, ... -> Problem: >2000 verschiedene Einheiten (zu viele) -> RecipeYield nicht verwenden\n",
    "-> Stattdessen auf RecipeServings zurückgreifen und fehlende Werte durch randomforest imputieren\n",
    "\n",
    "Wichtig: Da RecipeServings schlecht verteilt ist (z.b. meisten Werte zwischen 0 und 10, aber auch Werte >1000) werden die Modelle ungenau\n",
    "-> Lösung: Verwendung von Klassen: Einteilung in Serving-Size: small, medium, large, ...\n",
    "-> Wichtig: One-hot-encoding nutzen (da es sich um Kategorien handelt) -> 3 Spalten: small, medium, large\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "# Correlation Matrix von numerischen Werten\n",
    "# corr = recipes_data[[\"CookTime\", \"PrepTime\", \"Calories\", \"FatContent\", \"CarbohydrateContent\", \"FiberContent\", \"SugarContent\", \"ProteinContent\", \"RecipeServings\"]].corr(numeric_only=True)\n",
    "# print(corr)\n",
    "\n",
    "# RecipeYield\n",
    "# recipes_data[\"RecipeYield_Quantity\"] = recipes_data[\"RecipeYield\"].str.split(\" \").str[0]\n",
    "# recipes_data[\"RecipeYield_Unit\"] = recipes_data[\"RecipeYield\"].str.split(\" \").str[1]\n",
    "recipes_data.drop(columns=[\"RecipeYield\"], inplace=True)\n",
    "\n",
    "# Logarithmieren von RecipeServings, um die Verteilung zu verbessern\n",
    "recipes_data[\"RecipeServings\"] = recipes_data[\"RecipeServings\"].apply(lambda x: np.log(x) if x > 0 else x)\n",
    "\n",
    "# plt.figure(figsize=(10, 6))\n",
    "# plt.hist(recipes_data['RecipeServings'], bins=10)\n",
    "# plt.title('Histogram of Recipe Servings')\n",
    "# plt.xlabel('Recipe Servings')\n",
    "# plt.ylabel('Frequency')\n",
    "# plt.show()\n",
    "\n",
    "# Outlier weg\n",
    "std_RecipeServings = recipes_data[recipes_data['RecipeServings'].notna()][\"RecipeServings\"].std()\n",
    "mean_RecipeServings = recipes_data[recipes_data['RecipeServings'].notna()][\"RecipeServings\"].mean()\n",
    "# print(recipes_data['RecipeServings'].describe())\n",
    "\"\"\"\n",
    "mean         1.770398\n",
    "std          0.781950\n",
    "min          0.000000\n",
    "25%          1.386294 -> 25% der Werte sind 1.386294 oder kleiner -> small\n",
    "50%          1.791759 -> 50% der Werte sind 1.791759 oder kleiner -> medium\n",
    "75%          2.079442 -> 75% der Werte sind 2.079442 oder kleiner -> large\n",
    "max          6.907755\n",
    "\"\"\"\n",
    "\n",
    "upper_limit_RecipeServings = mean_RecipeServings + threshold * std_RecipeServings\n",
    "lower_limit_RecipeServings = mean_RecipeServings - threshold * std_RecipeServings\n",
    "\n",
    "recipes_data = recipes_data[((recipes_data[\"RecipeServings\"] >= lower_limit_RecipeServings) & (recipes_data['RecipeServings'] <= upper_limit_RecipeServings)) | (recipes_data['RecipeServings'].isna())]\n",
    "print(\"Shape nach Kürzung der Outlier: \", recipes_data.shape)\n",
    "\n",
    "recipes_data_description = recipes_data.describe()\n",
    "# Discretization von RecipeServings -> Klassen: small = 1, medium = 2, large = 3 -> one-hot-encoding\n",
    "recipes_data[\"RecipeServings_small\"] = recipes_data[\"RecipeServings\"].apply(lambda x: 1 if x <= recipes_data_description.loc[\"25%\", \"RecipeServings\"] else 0)\n",
    "recipes_data[\"RecipeServings_medium\"] = recipes_data[\"RecipeServings\"].apply(lambda x: 1 if (x > recipes_data_description.loc[\"25%\", \"RecipeServings\"]) & (x <= recipes_data_description.loc[\"75%\", \"RecipeServings\"]) else 0)\n",
    "recipes_data[\"RecipeServings_large\"] = recipes_data[\"RecipeServings\"].apply(lambda x: 1 if x > recipes_data_description.loc[\"75%\", \"RecipeServings\"] else 0)\n",
    "# print(recipes_data[['RecipeId', 'RecipeServings_small', 'RecipeServings_medium', 'RecipeServings_large']].head(10))\n",
    "# print(\"Anzahl small, medium, large: \", recipes_data[\"RecipeServings_small\"].sum(), recipes_data[\"RecipeServings_medium\"].sum(), recipes_data[\"RecipeServings_large\"].sum())\n",
    "\n",
    "# fehlende Werte in RecipeServings durch random forest imputieren\n",
    "features = ['CookTime', 'PrepTime', 'Calories', 'FatContent', 'FiberContent', 'ProteinContent']\n",
    "\n",
    "# test_data with and without RecipeServings, training_data only with RecipeServings\n",
    "known_servings = recipes_data[recipes_data['RecipeServings'].notna()]\n",
    "unknown_servings = recipes_data[recipes_data['RecipeServings'].isna()]\n",
    "\n",
    "X = known_servings[features]\n",
    "y_known = known_servings['RecipeServings_small']\n",
    "\n",
    "# print(X)\n",
    "# print(y_known)\n",
    "X_train, X_val, y_train, y_val = train_test_split(X, y_known, test_size=0.15, random_state=random_seed)\n",
    "# print('Training Features Shape:', X_train.shape)\n",
    "# print('Training Labels Shape:', y_train.shape)\n",
    "# print('Validation Features Shape:', X_val.shape)\n",
    "# print('Validation Labels Shape:', y_val.shape)\n",
    "\n",
    "\n",
    "# Model trainieren\n",
    "model = RandomForestRegressor(n_estimators=50, random_state=random_seed)\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "# Model evaluieren\n",
    "y_pred = model.predict(X_val)\n",
    "\n",
    "# Kategorisieren: Einteilung in am nächsten liegende Klasse\n",
    "for y in y_pred:\n",
    "    distance_small = np.absolute(recipes_data_description.loc[\"25%\", \"RecipeServings\"] - y)\n",
    "\n",
    "# Bewertung des Modells\n",
    "mse = mean_squared_error(y_val, y_pred)\n",
    "# calculate r squared\n",
    "r_squared = model.score(X_val, y_val)\n",
    "print('R Squared: ', r_squared)\n",
    "print('MSE Mean Squred Error: ', mse) \n",
    "\n",
    "\n",
    "# y_val together with y_pred \n",
    "y_val_pred = pd.DataFrame({'y_val': y_val, 'y_pred': y_pred})\n",
    "# Extract RecipeId for the validation set\n",
    "recipe_ids_val = recipes_data.loc[y_val.index, 'RecipeId']\n",
    "# Add RecipeId to the y_val_pred dataframe\n",
    "y_val_pred['RecipeId'] = recipe_ids_val\n",
    "\n",
    "# Display the dataframe\n",
    "print(y_val_pred.head(20))\n",
    "\n",
    "\n",
    "# Model anwenden um fehlende Daten zu analysieren\n",
    "# X_unknown = unknown_servings[features]\n",
    "# y_unknown = unknown_servings[\"RecipeServings\"]\n",
    "# y_unknown_pred = model.predict(X_unknown)\n",
    "\n",
    "# print(unknown_servings.head())\n",
    "# print(y_unknown_pred.head())\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# recipes_data[\"RecipeCategory\"].unique()\n",
    "# recipes_data.head()\n",
    "# recipes_data.dtypes\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## II. Feature Engineering\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## III. Data Integration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/ld/b6k2sw2912sg5m2xrc0hr5qh0000gn/T/ipykernel_57720/1139240406.py:5: DtypeWarning: Columns (3) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  reviews_df = pd.read_csv(\"../aufgabe/training_dataset/reviews.csv\")\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>AuthorId</th>\n",
       "      <th>RecipeId</th>\n",
       "      <th>Rating</th>\n",
       "      <th>Like</th>\n",
       "      <th>TestSetId</th>\n",
       "      <th>Diet</th>\n",
       "      <th>Age</th>\n",
       "      <th>Time</th>\n",
       "      <th>HighCalories</th>\n",
       "      <th>HighProtein</th>\n",
       "      <th>...</th>\n",
       "      <th>FatContent</th>\n",
       "      <th>SaturatedFatContent</th>\n",
       "      <th>CholesterolContent</th>\n",
       "      <th>SodiumContent</th>\n",
       "      <th>CarbohydrateContent</th>\n",
       "      <th>FiberContent</th>\n",
       "      <th>SugarContent</th>\n",
       "      <th>ProteinContent</th>\n",
       "      <th>RecipeServings</th>\n",
       "      <th>RecipeYield</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2492191A</td>\n",
       "      <td>33671</td>\n",
       "      <td>2.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "      <td>Omnivore</td>\n",
       "      <td>19</td>\n",
       "      <td>2698.714376</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Indifferent</td>\n",
       "      <td>...</td>\n",
       "      <td>37.8</td>\n",
       "      <td>17.1</td>\n",
       "      <td>96.6</td>\n",
       "      <td>1280.4</td>\n",
       "      <td>97.1</td>\n",
       "      <td>17.7</td>\n",
       "      <td>9.4</td>\n",
       "      <td>41.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2002019979A</td>\n",
       "      <td>92647</td>\n",
       "      <td>2.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2.0</td>\n",
       "      <td>Omnivore</td>\n",
       "      <td>66</td>\n",
       "      <td>2399.694583</td>\n",
       "      <td>1.0</td>\n",
       "      <td>Indifferent</td>\n",
       "      <td>...</td>\n",
       "      <td>18.2</td>\n",
       "      <td>6.1</td>\n",
       "      <td>71.1</td>\n",
       "      <td>1261.7</td>\n",
       "      <td>48.4</td>\n",
       "      <td>9.7</td>\n",
       "      <td>4.4</td>\n",
       "      <td>29.1</td>\n",
       "      <td>6.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>408594E</td>\n",
       "      <td>161770</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3.0</td>\n",
       "      <td>Omnivore</td>\n",
       "      <td>35</td>\n",
       "      <td>2099.113170</td>\n",
       "      <td>1.0</td>\n",
       "      <td>Indifferent</td>\n",
       "      <td>...</td>\n",
       "      <td>26.4</td>\n",
       "      <td>10.6</td>\n",
       "      <td>61.8</td>\n",
       "      <td>1370.2</td>\n",
       "      <td>11.5</td>\n",
       "      <td>2.6</td>\n",
       "      <td>4.9</td>\n",
       "      <td>23.1</td>\n",
       "      <td>4.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2001625557E</td>\n",
       "      <td>108231</td>\n",
       "      <td>2.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>4.0</td>\n",
       "      <td>Omnivore</td>\n",
       "      <td>76</td>\n",
       "      <td>1199.645575</td>\n",
       "      <td>1.0</td>\n",
       "      <td>Yes</td>\n",
       "      <td>...</td>\n",
       "      <td>128.2</td>\n",
       "      <td>64.7</td>\n",
       "      <td>320.1</td>\n",
       "      <td>757.9</td>\n",
       "      <td>14.6</td>\n",
       "      <td>1.6</td>\n",
       "      <td>8.7</td>\n",
       "      <td>20.6</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2 cups</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2001427116E</td>\n",
       "      <td>71109</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>5.0</td>\n",
       "      <td>Omnivore</td>\n",
       "      <td>56</td>\n",
       "      <td>2341.181827</td>\n",
       "      <td>1.0</td>\n",
       "      <td>Indifferent</td>\n",
       "      <td>...</td>\n",
       "      <td>8.5</td>\n",
       "      <td>1.4</td>\n",
       "      <td>68.4</td>\n",
       "      <td>662.4</td>\n",
       "      <td>5.4</td>\n",
       "      <td>1.1</td>\n",
       "      <td>1.9</td>\n",
       "      <td>29.4</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4 Breast halves</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>140190</th>\n",
       "      <td>999595E</td>\n",
       "      <td>338070</td>\n",
       "      <td>2.0</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Vegetarian</td>\n",
       "      <td>31</td>\n",
       "      <td>3899.421310</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Indifferent</td>\n",
       "      <td>...</td>\n",
       "      <td>31.4</td>\n",
       "      <td>15.0</td>\n",
       "      <td>99.8</td>\n",
       "      <td>391.7</td>\n",
       "      <td>43.1</td>\n",
       "      <td>1.4</td>\n",
       "      <td>27.3</td>\n",
       "      <td>5.2</td>\n",
       "      <td>16.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>140191</th>\n",
       "      <td>999774A</td>\n",
       "      <td>29002</td>\n",
       "      <td>2.0</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Vegetarian</td>\n",
       "      <td>57</td>\n",
       "      <td>2402.372535</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Indifferent</td>\n",
       "      <td>...</td>\n",
       "      <td>33.3</td>\n",
       "      <td>8.5</td>\n",
       "      <td>33.2</td>\n",
       "      <td>318.2</td>\n",
       "      <td>107.7</td>\n",
       "      <td>10.3</td>\n",
       "      <td>13.5</td>\n",
       "      <td>32.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>140192</th>\n",
       "      <td>999774A</td>\n",
       "      <td>159252</td>\n",
       "      <td>NaN</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Vegetarian</td>\n",
       "      <td>57</td>\n",
       "      <td>5999.598903</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Yes</td>\n",
       "      <td>...</td>\n",
       "      <td>0.6</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>6.8</td>\n",
       "      <td>240.4</td>\n",
       "      <td>7.0</td>\n",
       "      <td>229.8</td>\n",
       "      <td>1.1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>4 cups</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>140193</th>\n",
       "      <td>999774A</td>\n",
       "      <td>1171</td>\n",
       "      <td>2.0</td>\n",
       "      <td>True</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Vegetarian</td>\n",
       "      <td>57</td>\n",
       "      <td>480.233207</td>\n",
       "      <td>1.0</td>\n",
       "      <td>Yes</td>\n",
       "      <td>...</td>\n",
       "      <td>19.8</td>\n",
       "      <td>12.2</td>\n",
       "      <td>68.3</td>\n",
       "      <td>247.4</td>\n",
       "      <td>87.5</td>\n",
       "      <td>4.0</td>\n",
       "      <td>57.8</td>\n",
       "      <td>18.2</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2 mugs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>140194</th>\n",
       "      <td>999917E</td>\n",
       "      <td>169413</td>\n",
       "      <td>2.0</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Vegetarian</td>\n",
       "      <td>28</td>\n",
       "      <td>3600.387748</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Indifferent</td>\n",
       "      <td>...</td>\n",
       "      <td>8.6</td>\n",
       "      <td>4.7</td>\n",
       "      <td>66.5</td>\n",
       "      <td>521.9</td>\n",
       "      <td>24.8</td>\n",
       "      <td>1.7</td>\n",
       "      <td>3.4</td>\n",
       "      <td>5.6</td>\n",
       "      <td>8.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>140195 rows × 30 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           AuthorId  RecipeId  Rating   Like  TestSetId        Diet  Age  \\\n",
       "0          2492191A     33671     2.0    NaN        1.0    Omnivore   19   \n",
       "1       2002019979A     92647     2.0    NaN        2.0    Omnivore   66   \n",
       "2           408594E    161770     NaN    NaN        3.0    Omnivore   35   \n",
       "3       2001625557E    108231     2.0    NaN        4.0    Omnivore   76   \n",
       "4       2001427116E     71109     NaN    NaN        5.0    Omnivore   56   \n",
       "...             ...       ...     ...    ...        ...         ...  ...   \n",
       "140190      999595E    338070     2.0  False        NaN  Vegetarian   31   \n",
       "140191      999774A     29002     2.0  False        NaN  Vegetarian   57   \n",
       "140192      999774A    159252     NaN  False        NaN  Vegetarian   57   \n",
       "140193      999774A      1171     2.0   True        NaN  Vegetarian   57   \n",
       "140194      999917E    169413     2.0  False        NaN  Vegetarian   28   \n",
       "\n",
       "               Time  HighCalories  HighProtein  ...  FatContent  \\\n",
       "0       2698.714376           0.0  Indifferent  ...        37.8   \n",
       "1       2399.694583           1.0  Indifferent  ...        18.2   \n",
       "2       2099.113170           1.0  Indifferent  ...        26.4   \n",
       "3       1199.645575           1.0          Yes  ...       128.2   \n",
       "4       2341.181827           1.0  Indifferent  ...         8.5   \n",
       "...             ...           ...          ...  ...         ...   \n",
       "140190  3899.421310           0.0  Indifferent  ...        31.4   \n",
       "140191  2402.372535           0.0  Indifferent  ...        33.3   \n",
       "140192  5999.598903           0.0          Yes  ...         0.6   \n",
       "140193   480.233207           1.0          Yes  ...        19.8   \n",
       "140194  3600.387748           0.0  Indifferent  ...         8.6   \n",
       "\n",
       "       SaturatedFatContent  CholesterolContent SodiumContent  \\\n",
       "0                     17.1                96.6        1280.4   \n",
       "1                      6.1                71.1        1261.7   \n",
       "2                     10.6                61.8        1370.2   \n",
       "3                     64.7               320.1         757.9   \n",
       "4                      1.4                68.4         662.4   \n",
       "...                    ...                 ...           ...   \n",
       "140190                15.0                99.8         391.7   \n",
       "140191                 8.5                33.2         318.2   \n",
       "140192                 0.1                 0.0           6.8   \n",
       "140193                12.2                68.3         247.4   \n",
       "140194                 4.7                66.5         521.9   \n",
       "\n",
       "        CarbohydrateContent  FiberContent SugarContent ProteinContent  \\\n",
       "0                      97.1          17.7          9.4           41.0   \n",
       "1                      48.4           9.7          4.4           29.1   \n",
       "2                      11.5           2.6          4.9           23.1   \n",
       "3                      14.6           1.6          8.7           20.6   \n",
       "4                       5.4           1.1          1.9           29.4   \n",
       "...                     ...           ...          ...            ...   \n",
       "140190                 43.1           1.4         27.3            5.2   \n",
       "140191                107.7          10.3         13.5           32.0   \n",
       "140192                240.4           7.0        229.8            1.1   \n",
       "140193                 87.5           4.0         57.8           18.2   \n",
       "140194                 24.8           1.7          3.4            5.6   \n",
       "\n",
       "       RecipeServings      RecipeYield  \n",
       "0                 4.0              NaN  \n",
       "1                 6.0              NaN  \n",
       "2                 4.0              NaN  \n",
       "3                 NaN           2 cups  \n",
       "4                 4.0  4 Breast halves  \n",
       "...               ...              ...  \n",
       "140190           16.0              NaN  \n",
       "140191            4.0              NaN  \n",
       "140192            NaN           4 cups  \n",
       "140193            1.0           2 mugs  \n",
       "140194            8.0              NaN  \n",
       "\n",
       "[140195 rows x 30 columns]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Laden der Datensätze\n",
    "diet_df = pd.read_csv(\"../aufgabe/training_dataset/diet.csv\")\n",
    "recipes_df = pd.read_csv(\"../aufgabe/training_dataset/recipes.csv\")\n",
    "requests_df = pd.read_csv(\"../aufgabe/training_dataset/requests.csv\")\n",
    "reviews_df = pd.read_csv(\"../aufgabe/training_dataset/reviews.csv\")\n",
    "\n",
    "# Anzeigen der ersten Reihen jedes Dataframes, um ihre Struktur zu verstehen\n",
    "diet_df.head(), recipes_df.head(), requests_df.head(), reviews_df.head()\n",
    "\n",
    "# Verbinden von reviews_df mit diet_df über AuthorId\n",
    "combined_df1 = pd.merge(reviews_df, diet_df, on='AuthorId', how='left')\n",
    "\n",
    "# Verbinden von combined_df1 mit requests_df über AuthorId und RecipeId\n",
    "combined_df2 = pd.merge(combined_df1, requests_df, on=['AuthorId', 'RecipeId'], how='left')\n",
    "\n",
    "# Verbinden von combined_df2 mit recipes_df über RecipeId\n",
    "final_combined_df = pd.merge(combined_df2, recipes_df, on='RecipeId', how='left')\n",
    "\n",
    "# Anzeigen der ersten Reihen des endgültigen integrierten Datensatzes\n",
    "final_combined_df\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ac-cup-venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
